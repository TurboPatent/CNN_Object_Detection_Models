<p>
  <span data-role="tag" data-value="f7e3b89b-ae15-dcc2-30a4-ceed984e8ecf" id="iddcaeb4b8-b0d0-1070-ccd0-85cc0af5a3ce" data-type="figure">Figure 2</span>&nbsp;illustrates an example of a&nbsp;
  <span data-role="tag" data-value="b4d64ca4-7582-c989-dd04-e059fb3f7268" id="id7a08c885-48c7-be62-afc5-866cb0f2ad05" data-type="drawingObject">Region-based Convolution Network 200</span>&nbsp;(R-CNN).&nbsp;Each region proposal feeds a convolutional neural network (CNN) to extract a features vector, possible objects are detected using multiple SVM classifiers and a linear regressor modifies the coordinates of the bounding box.&nbsp;The regions of interest (
  <span data-role="tag" data-value="404f79c4-2099-5093-441c-2491cc83194d" id="ide042b8b4-fa42-cbdb-8742-38a749fe9b25" data-type="drawingObject">ROI 202</span>) of the 
  <span data-role="tag" data-value="6523ccea-36a7-e24e-c265-bd74404dbd88" id="idedb9c996-1571-5b6d-aeba-533a6a934169" data-type="drawingObject">input image 204</span>. Each&nbsp;
  <span data-role="tag" data-value="404f79c4-2099-5093-441c-2491cc83194d" id="idbe353fb0-e9e1-2276-9748-90593262531d" data-type="drawingObject">ROI 202</span>&nbsp;of&nbsp; resized/warped creating the&nbsp;
  <span data-role="tag" data-value="9552cf1d-7e6f-6752-ae2a-cddcedb388f3" id="idc3dde138-41fc-ea9f-91de-04d49134ae3a" data-type="drawingObject">warped image region 206</span>&nbsp;which are forwarded to the 
  <span data-role="tag" data-value="5e5c88ce-33b7-6e7f-5e5f-9a5316e7410b" id="id07260a5e-360f-4d75-5f5d-98fde9bbc99a" data-type="drawingObject">convolutional neural network 208</span>&nbsp;where they are feed to the 
  <span data-role="tag" data-value="709b20c0-03a2-e44b-f39c-998795032d9f" id="id38e71968-cc2f-799b-990f-0485253ed7e5" data-type="drawingObject">support vector machines 212</span>&nbsp;and 
  <span data-role="tag" data-value="129f3008-56d3-0586-11ac-7749c3ccaaf8" id="id34f26ae6-95c5-0522-74d4-009604262c78" data-type="drawingObject">bounding box linear regressors 210</span>.
</p>
<p>In R-CNN, the&nbsp;selective search&nbsp;method&nbsp;is an alternative to exhaustive search in an image to capture object location. It initializes small regions in an image and merges them with a hierarchical grouping. Thus the final group is a box containing the entire image. The detected regions are merged according to a variety of color spaces and similarity metrics. The output is a few number of region proposals which could contain an object by merging small regions.</p>
<p>The R-CNN model&nbsp;combines the&nbsp;selective search method to detect region proposals and deep learning to find out the object in these regions. Each region proposal is resized to match the input of a CNN from which the method extracts a 4096-dimension vector of features. The features vector is fed into multiple classifiers to produce probabilities to belong to each class. Each one of these classes has a 
  <span data-role="tag" data-value="709b20c0-03a2-e44b-f39c-998795032d9f" id="idd624260b-4fe4-619d-99a9-3eeeffaa9309" data-type="drawingObject">support vector machines 212</span>&nbsp;(SVM) classifier trained to infer a probability to detect this object for a given vector of features. This vector also feeds a linear regressor to adapt the shapes of the bounding box for a region proposal and thus reduce localization errors.
</p>
<p>The CNN model described is trained on the ImageNet dataset. It is fine-tuned using the region proposals corresponding to an IoU greater than 0.5 with the ground-truth boxes. Two versions are produced, one version is using the PASCAL VOC dataset and the other the ImageNet dataset with bounding boxes. The SVM classifiers are also trained for each class of each dataset.</p>