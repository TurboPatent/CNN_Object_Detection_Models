<p>
  <span data-role="tag" data-value="02549bfa-95d5-5d10-7432-ea2c3eef9ebf" id="id474e5ac2-2e4c-043c-cd9b-5d7b2d6921b4" data-type="figure">Figure 3</span>&nbsp;illustrates an example of a&nbsp;
  <span data-role="tag" data-value="577cce73-5128-f71f-3458-a2a4bd854036" id="id0ae3856d-e255-14f3-df12-cab35682b7ef" data-type="drawingObject">Fast Region-based Convolutional Network 300</span>&nbsp;(Fast R-CNN). The entire image (
  <span data-role="tag" data-value="3377eb61-eac2-9d0d-162d-54b7dcbf24b1" id="id49ad8b54-4e81-09ef-c54b-d28db79ecafc" data-type="drawingObject">input image 306</span>) feeds a CNN model (
  <span data-role="tag" data-value="b9a4de73-54b2-f242-d75b-4a281e6f9081" id="idc572d441-0c9f-e067-e0d4-69dde788e432" data-type="drawingObject">convolutional neural network 302</span>) to detect RoI (
  <span data-role="tag" data-value="40091d1e-d7f3-5fe7-36bc-08168f8ab7f5" id="idbd392df4-7cab-7265-3104-9b4d0bfca4c4" data-type="drawingObject">ROI 304</span>) on the&nbsp;
  <span data-role="tag" data-value="14dd6d6d-24b2-e29c-6545-18a06889b276" id="ida0aef381-1926-0fee-e706-4713a0d66508" data-type="drawingObject">feature maps 310</span>. Each region is separated using a RoI pooling layer (
  <span data-role="tag" data-value="2a82d3d6-6ad7-b11d-2e99-d495a920811c" id="idb3a7b946-a2d8-f441-dd7d-d51e76752c94" data-type="drawingObject">ROI pooling layer 308</span>) and it feeds&nbsp;
  <span data-role="tag" data-value="28608637-1b87-924c-61ff-e1cad8d47bc2" id="idcff1c524-20f9-450c-915c-94d89411742e" data-type="drawingObject">fully connected layers 312</span>. This vector is used by a&nbsp;
  <span data-role="tag" data-value="ac601c0a-aac8-95b2-9fb0-24082c0f4dec" id="idf1bd4eb0-a3b7-0174-0e94-a9017611960c" data-type="drawingObject">softmax classifier 314</span> to detect the object and by a 
  <span data-role="tag" data-value="06d11791-5178-e3ee-0c99-c2c04452e902" id="idce76bc30-e375-ce05-92d8-d3cb300cda9b" data-type="drawingObject">bounding box linear regressors 316</span> to modify the coordinates of the bounding box. The purpose of the Fast R-CNN&nbsp;is to reduce the time consumption related to the high number of models necessary to analyse all region proposals.
</p>
<p>A main CNN with multiple convolutional layers is taking the entire image as input instead of using a CNN for each region proposals (R-CNN).&nbsp;Region of Interests&nbsp;(RoIs) are detected with the selective search method applied on the produced feature maps. Formally, the feature maps size is reduced using a RoI pooling layer to get valid Region of Interests with fixed height and width as hyperparameters. Each RoI layer feeds fully-connected layers&nbsp;creating a features vector. The vector is used to predict the observed object with a softmax classifier and to adapt bounding box localizations with a linear regressor.</p>